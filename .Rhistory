View(data)
View(data)
data <- data[,2:4]
View(data)
d_clean= apply(data[,1],1,Clean_Text_Block)
len_words=sapply(d_clean, '[[', 1)
words= sapply(d_clean, '[[', 3)
max.length <- max(sapply(words, length))
words <- lapply(words, function(v) { c(v, rep(NA, max.length-length(v)))})
words= do.call(rbind, words)
clean_words_counts=  cbind(words[,2:ncol(words)])
rm(words)
rm(d_clean)
rm(max.length)
library(urltools)
dt <- matrix(0,nrow(data),1)
for (i in 1:nrow(data[,1]))
{
dt[i,1]=as.character(data[i,1])
}
parsed_dt <- url_parse(dt)
clean_parsed_dt <- cbind(parsed_dt[,1],parsed_dt[,2],parsed_dt[,4])
rm(dt)
rm(parsed_dt)
rm(i)
final_dt <- cbind (clean_parsed_dt, clean_words_counts)
rm(clean_parsed_dt)
rm(clean_words_counts)
final_dt[is.na(final_dt)] <- 0
len_final_dt=sapply(final_dt,nchar)
dim(len_final_dt) <- c(nrow(final_dt),ncol(final_dt))
num_dt <- as.factor(final_dt)
levels(num_dt) <- 1:length(levels(num_dt))
num_dt <- as.numeric(num_dt)
dim(num_dt) <- c(nrow(final_dt),ncol(final_dt))
final_num_dt <- cbind(num_dt[,2:ncol(num_dt)],len_words)
final_num_dt[is.na(final_num_dt)] <- 0
all_num_len <- cbind(final_num_dt, len_final_dt)
rm(num_dt)
rm(len_words)
original_data <- cbind (all_num_len, data[,2])
View(original_data)
head(original_data)
require(caTools)
library(matrixStats)
library(dplyr)
library(plyr)
max_mu <- function (x)
{
mu<- colMeans(as.matrix(x))
max_mu= matrix(0,nrow=nrow(x),ncol=ncol(x))
for(r in 1:nrow(x))
{
for( c in 1:ncol(x))
{
max_mu[r,c]= mu[c]
}
}
return(max_mu)
}
#estimatining std
max_sd <- function (x)
{
std<- colSds(as.matrix(x))
max_std=matrix(0,nrow=nrow(x),ncol=ncol(x))
for(r in 1:nrow(x))
{
for( c in 1:ncol(x))
{
max_std[r,c]= std[c]
}
}
return(max_std)
}
# estimate density that will be the input of GMA-HMM
mix_density <- function (x,mu,std)
{
den_mr=matrix(0,nrow=nrow(x),ncol=ncol(x))
for(r in 1:nrow(x))
{
for( c in 1:ncol(x))
{
den_mr[r,c]<- rnorm(x[r,c],mu[r,c],std[r,c])
}
}
return(den_mr)
}
View(final_dt)
mu=ddply( original_data[,1:322], .(dt_lb[,323]), max_mu) # estimate mu based on types
mu=ddply( original_data[,1:322], .(original_data[,323]), max_mu) # estimate mu based on types
std=ddply(original_data[,1:322], .(original_data[,323]), max_sd) # estimate std based on types
dt_mu=as.matrix(mu[,2:29])    #
dt_sd= as.matrix(std[,2:29])  #
dt_mu=dt_mu[!duplicated(dt_mu), ]
dt_sd= dt_sd[!duplicated(dt_sd), ]
View(dt_mu)
View(data)
X <- seq(min(original_data),max(original_data),length = 28000)       # x
simulated_attacks <-  abs(rnorm(X, mean = mean(dt_mu[2,]), sd = sd(dt_sd[2,]))) # attack
dim(simulated_attacks) <- c(1000,28)
label= rep(1, nrow(simulated_attacks)) # attack label
simulated_attacks=cbind(simulated_attacks,label)
simulated_normal <- abs(rnorm(X, mean = mean(dt_mu[1,]), sd = sd(dt_sd[1,]))) #normal
dim(simulated_normal) <- c(1000,28)
label= rep(0, nrow(simulated_attacks)) # attack label
simulated_normal=cbind(simulated_normal,label)
simulated_data= rbind(simulated_attacks,simulated_normal)
View(simulated_normal)
10000*323
X <- seq(min(original_data),max(original_data),length = 3230000)       # x
simulated_attacks <-  abs(rnorm(X, mean = mean(dt_mu[2,]), sd = sd(dt_sd[2,]))) # attack
dim(simulated_attacks) <- c(10000,323)
label= rep(1, nrow(simulated_attacks)) # attack label
simulated_attacks=cbind(simulated_attacks,label)
simulated_normal <- abs(rnorm(X, mean = mean(dt_mu[1,]), sd = sd(dt_sd[1,]))) #normal
dim(simulated_normal) <- c(10000,323)
label= rep(0, nrow(simulated_attacks)) # attack label
simulated_normal=cbind(simulated_normal,label)
simulated_data= rbind(simulated_attacks,simulated_normal)
View(simulated_normal)
head(simulated_data)
set.seed(101)
sample = sample.split(original_data$Label, SplitRatio = .70)
train = subset(dt_lb, sample == TRUE)
test  = subset(dt_lb, sample == FALSE)
original_data$Label
attach(original_data)
original_data$Label
head(original_data)
original_data['Phishing'] <- 'Label'
original_data$Label
head(original_data)
library(readr)
library(urltools)
library(caret)
library(caTools)
library(e1071)
data <- read_csv("E:/My-papers/Cyber-Simulation/Phishing-Simulation-Modeling/data1.csv")
View(data)
data <- data[,2:4]
#####################################
Clean_String <- function(string){
# Lowercase
temp <- tolower(string)
#' Remove everything that is not a number or letter (may want to keep more
#' stuff in your actual analyses).
temp <- stringr::str_replace_all(temp,"[^a-zA-Z\\s]", " ")
# Shrink down to just one white space
temp <- stringr::str_replace_all(temp,"[\\s]+", " ")
# Split it
temp <- stringr::str_split(temp, " ")[[1]]
# Get rid of trailing "" if necessary
indexes <- which(temp == "")
if(length(indexes) > 0){
temp <- temp[-indexes]
}
return(temp)
}
##################################
#' function to clean text
Clean_Text_Block <- function(text){
if(length(text) <= 1){
# Check to see if there is any text at all with another conditional
if(length(text) == 0){
cat("There was no text in this document! \n")
to_return <- list(num_tokens = 0, unique_tokens = 0, text = "")
}else{
# If there is , and only only one line of text then tokenize it
clean_text <- Clean_String(text)
num_tok <- length(clean_text)
num_uniq <- length(unique(clean_text))
to_return <- list(num_tokens = num_tok, unique_tokens = num_uniq, text = clean_text)
}
}else{
# Get rid of blank lines
indexes <- which(text == "")
if(length(indexes) > 0){
text <- text[-indexes]
}
# Loop through the lines in the text and use the append() function to
clean_text <- Clean_String(text[1])
for(i in 2:length(text)){
# add them to a vector
clean_text <- append(clean_text,Clean_String(text[i]))
}
# Calculate the number of tokens and unique tokens and return them in a
# named list object.
num_tok <- length(clean_text)
num_uniq <- length(unique(clean_text))
to_return <- list(num_tokens = num_tok, unique_tokens = num_uniq, text = clean_text)
}
return(to_return)
}
#############################
### gettring words and their count
d_clean= apply(data[,1],1,Clean_Text_Block)
len_words=sapply(d_clean, '[[', 1)
words= sapply(d_clean, '[[', 3)
max.length <- max(sapply(words, length))
## Add NA values to list elements
words <- lapply(words, function(v) { c(v, rep(NA, max.length-length(v)))})
## Rbind
words= do.call(rbind, words)
#words[is.na(words)] <- 0
clean_words_counts=  cbind(words[,2:ncol(words)])
rm(words)
rm(d_clean)
#rm(len_words)
rm(max.length)
######################################################
# getting scheme, domain, path
library(urltools)
dt <- matrix(0,nrow(data),1)
for (i in 1:nrow(data[,1]))
{
dt[i,1]=as.character(data[i,1])
}
parsed_dt <- url_parse(dt)
#parsed_dt[is.na(parsed_dt)] <- 0
clean_parsed_dt <- cbind(parsed_dt[,1],parsed_dt[,2],parsed_dt[,4])
rm(dt)
rm(parsed_dt)
rm(i)
#############################################
# final string attributes
final_dt <- cbind (clean_parsed_dt, clean_words_counts)
rm(clean_parsed_dt)
rm(clean_words_counts)
#############################################
# lenght of data
final_dt[is.na(final_dt)] <- 0
len_final_dt=sapply(final_dt,nchar)
dim(len_final_dt) <- c(nrow(final_dt),ncol(final_dt))
### convert data to numeric
num_dt <- as.factor(final_dt)
levels(num_dt) <- 1:length(levels(num_dt))
num_dt <- as.numeric(num_dt)
dim(num_dt) <- c(nrow(final_dt),ncol(final_dt))
final_num_dt <- cbind(num_dt[,2:ncol(num_dt)],len_words)
final_num_dt[is.na(final_num_dt)] <- 0
# 14 numeric +noofwords+len of 14 attributes
all_num_len <- cbind(final_num_dt, len_final_dt)
rm(num_dt)
rm(len_words)
### data with label
original_data <- cbind (all_num_len, data[,2])
head(original_data)
#dt_lb <- cbind (final_num_dt, data[,2],data[,3])
#dt_lb <- cbind (final_num_dt, data[,2])
original_data$Phishing
sample = sample.split(original_data$Phishing, SplitRatio = .70)
train = subset(original_data, sample == TRUE)
test  = subset(original_data, sample == FALSE)
head(original_data)
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
attach(original_data)
set.seed(7)
fit.lda <- train(as.factor(Label)~., data=train1, method="lda", metric=metric, trControl=control)
# b) nonlinear algorithms
# CART
fit.lda <- train(as.factor(Label)~., data=train, method="lda", metric=metric, trControl=control)
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
fit.lda <- train(as.factor(Phishing)~., data=train, method="lda", metric=metric, trControl=control)
View(train)
fit.lda <- train(as.factor(Phishing)~., data=train, method="lda", metric=metric, trControl=control)
set.seed(7)
fit.cart <- train(as.factor(Phishing)~., data=train, method="rpart", metric=metric, trControl=control)
set.seed(7)
fit.knn <- train(as.factor(Phishing)~., data=train, method="knn", metric=metric, trControl=control)
set.seed(7)
fit.svm <- train(as.factor(Phishing)~., data=train, method="svmRadial", metric=metric, trControl=control)
set.seed(7)
fit.rf <- train(as.factor(Phishing)~., data=train, method="rf", metric=metric, trControl=control)
pred_lda <- predict(fit.lda, test)
lda_c<- confusionMatrix(pred_lda, test$Label)
lda_c
pred_cart <- predict(fit.cart, test)
lda_cart<- confusionMatrix(pred_cart, test$Label)
lda_cart
pred_knn <- predict(fit.knn, test)
lda_knn<- confusionMatrix(pred_knn, test$Label)
lda_knn
pred_svm <- predict(fit.svm, test)
lda_svm<- confusionMatrix(pred_svm, test$Label)
lda_svm
pred_rf <- predict(fit.rf, test)
lda_rf<- confusionMatrix(pred_rf, test$Label)
lda_rf
pred_cart <- predict(fit.cart, test)
lda_cart<- confusionMatrix(pred_cart, test$Phishing)
lda_cart
pred_knn <- predict(fit.knn, test)
lda_knn<- confusionMatrix(pred_knn, test$Phishing)
lda_knn
pred_svm <- predict(fit.svm, test)
lda_svm<- confusionMatrix(pred_svm, test$Phishing)
lda_svm
pred_rf <- predict(fit.rf, test)
lda_rf<- confusionMatrix(pred_rf, test$Phishing)
lda_rf
lda_cart
lda_cart
lda_knn
lda_svm
View(final_num_dt)
head(final_num_dt)
original_data <- cbind (final_num_dt, data[,2])
View(original_data)
mu=ddply( original_data[,1:161], .(original_data[,162]), max_mu) # estimate mu based on types
std=ddply(original_data[,1:161], .(original_data[,162]), max_sd) # estimate std based on types
mu=ddply( original_data[,1:161], .(original_data[,162]), max_mu) # estimate mu based on types
std=ddply(original_data[,1:161], .(original_data[,162]), max_sd) # estimate std based on types
dt_mu=as.matrix(mu[,2:161])    #
dt_sd= as.matrix(std[,2:161])  #
dt_mu=dt_mu[!duplicated(dt_mu), ]
dt_sd= dt_sd[!duplicated(dt_sd), ]
dt_mu
View(dt_mu)
dt_mu=as.matrix(mu[,1:161])    #
dt_sd= as.matrix(std[,1:161])  #
dt_mu=dt_mu[!duplicated(dt_mu), ]
dt_sd= dt_sd[!duplicated(dt_sd), ]
10000*161
mu=ddply( original_data[,1:161], .(original_data[,162]), max_mu) # estimate mu based on types
std=ddply(original_data[,1:161], .(original_data[,162]), max_sd) # estimate std based on types
dt_mu=as.matrix(mu[,1:161])    #
dt_sd= as.matrix(std[,1:161])  #
dt_mu=dt_mu[!duplicated(dt_mu), ]
dt_sd= dt_sd[!duplicated(dt_sd), ]
#1000*323 simulate 10000 record with 28 varaibles
X <- seq(min(original_data),max(original_data),length = 1610000)       # x
simulated_attacks <-  abs(rnorm(X, mean = mean(dt_mu[2,]), sd = sd(dt_sd[2,]))) # attack
dim(simulated_attacks) <- c(10000,161)
label= rep(1, nrow(simulated_attacks)) # attack label
simulated_attacks=cbind(simulated_attacks,label)
simulated_normal <- abs(rnorm(X, mean = mean(dt_mu[1,]), sd = sd(dt_sd[1,]))) #normal
dim(simulated_normal) <- c(10000,161)
label= rep(0, nrow(simulated_attacks)) # attack label
simulated_normal=cbind(simulated_normal,label)
simulated_data= rbind(simulated_attacks,simulated_normal)
head(simulated_data)
set.seed(101)
head(original_data)
sample = sample.split(original_data$Phishing, SplitRatio = .70)
train = subset(original_data, sample == TRUE)
test  = subset(original_data, sample == FALSE)
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
attach(original_data)
set.seed(7)
fit.lda <- train(as.factor(Phishing)~., data=train, method="lda", metric=metric, trControl=control)
set.seed(7)
fit.cart <- train(as.factor(Phishing)~., data=train, method="rpart", metric=metric, trControl=control)
set.seed(7)
fit.knn <- train(as.factor(Phishing)~., data=train, method="knn", metric=metric, trControl=control)
set.seed(7)
fit.svm <- train(as.factor(Phishing)~., data=train, method="svmRadial", metric=metric, trControl=control)
set.seed(7)
fit.rf <- train(as.factor(Phishing)~., data=train, method="rf", metric=metric, trControl=control)
results <- resamples(list(lda=fit.lda, cart=fit.cart, knn=fit.knn, svm=fit.svm, rf=fit.rf))
summary(results)
dotplot(results)
print(fit.lda)
print(fit.cart)
print(fit.knn)
print(fit.svm)
print(fit.rf)
pred_lda <- predict(fit.lda, test)
lda_c<- confusionMatrix(pred_lda, test$Label)
lda_c
pred_cart <- predict(fit.cart, test)
lda_cart<- confusionMatrix(pred_cart, test$Phishing)
lda_cart
pred_knn <- predict(fit.knn, test)
lda_knn<- confusionMatrix(pred_knn, test$Phishing)
lda_knn
pred_svm <- predict(fit.svm, test)
lda_svm<- confusionMatrix(pred_svm, test$Phishing)
lda_svm
pred_rf <- predict(fit.rf, test)
lda_rf<- confusionMatrix(pred_rf, test$Phishing)
lda_rf
pred_lda <- predict(fit.lda, test)
lda_c<- confusionMatrix(pred_lda, test$Label)
lda_c
pred_cart <- predict(fit.cart, test)
lda_cart<- confusionMatrix(pred_cart, test$Phishing)
lda_cart
pred_knn <- predict(fit.knn, test)
lda_knn<- confusionMatrix(pred_knn, test$Phishing)
lda_knn
pred_svm <- predict(fit.svm, test)
lda_svm<- confusionMatrix(pred_svm, test$Phishing)
lda_svm
pred_rf <- predict(fit.rf, test)
lda_rf<- confusionMatrix(pred_rf, test$Phishing)
lda_rf
n1 = length(UN)
probabilities1 = (1:n1)/(n1+1)
normal.quantiles1 = qnorm(probabilities1, mean(UN, na.rm = T), sd(UN, na.rm = T))
plot(sort(normal.quantiles1), sort(UN) , xlab = '',lwd=2,
ylab = 'Quantiles of normal NSLKDD  ', main = '',col=4)
abline(0,1,col=2,lwd=2)
n2 = length(UN1)
probabilities2 = (1:n2)/(n2+1)
normal.quantiles1 = qnorm(probabilities2, mean(UN1, na.rm = T), sd(UN1, na.rm = T))
plot(sort(normal.quantiles1), sort(UN1) , xlab = '',lwd=2,
ylab = 'Quantiles of abnormal NSLKDD  ', main = '',col=4)
abline(0,1,col=2,lwd=2)
f=`unsw-normal`
UN=nsl.train.vectors[1:44,1]
UN1=nsl.test.test[1:44,1]
par(mfrow=c(1,2))
n1 = length(UN)
probabilities1 = (1:n1)/(n1+1)
normal.quantiles1 = qnorm(probabilities1, mean(UN, na.rm = T), sd(UN, na.rm = T))
plot(sort(normal.quantiles1), sort(UN) , xlab = '',lwd=2,
ylab = 'Quantiles of normal NSLKDD  ', main = '',col=4)
abline(0,1,col=2,lwd=2)
n2 = length(UN1)
probabilities2 = (1:n2)/(n2+1)
normal.quantiles1 = qnorm(probabilities2, mean(UN1, na.rm = T), sd(UN1, na.rm = T))
plot(sort(normal.quantiles1), sort(UN1) , xlab = '',lwd=2,
ylab = 'Quantiles of abnormal NSLKDD  ', main = '',col=4)
abline(0,1,col=2,lwd=2)
library(ggplot2)
library(plotROC)
### phishtank and DMOZ dataset
## Original data
set.seed(2529)
lb <- rbinom(300, size = 1, prob = .5)
Cart <- rnorm(300, mean = lb, sd = 0.50)
KNN<- rnorm(300, mean = lb, sd = 0.58)
SVM <- rnorm(300, mean = lb, sd = 0.56)
RF <- rnorm(300, mean = lb, sd = 0.40)
GMTD <- rnorm(300, mean = lb, sd = 0.33)
testd <- data.frame(D = lb, D.str = c("normal", "phishing")[lb + 1],
"cl1" = Cart,"cl2"= KNN, "cl3"= SVM, "cl4"= RF, "cl5"=GMTD, stringsAsFactors = FALSE)
colnames(testd) <- c("D","Dr_str","Cart", "KNN", "SVM","RF","Our OGM")
longtest <- melt_roc(testd, "D", c("Cart", "KNN", "SVM","RF","Our OGM"))
ggplot(longtest, aes(d = D, m = M, color = name,linetype=name))+ ggtitle("Original data")  + theme_bw()+
geom_roc(n.cuts = 0) + style_roc(theme =theme_bw(), xlab = "False Alarm Rate (%)", ylab="Detection Rate (%)") +
theme(legend.title=element_blank(), plot.title = element_text(hjust = 0.5, size=14,face="bold"), axis.text=element_text(size=12),axis.title=element_text(size=12,face="bold"))
### phishtank and DMOZ dataset
## Original data
set.seed(2529)
lb <- rbinom(300, size = 1, prob = .5)
Cart <- rnorm(300, mean = lb, sd = 0.50)
KNN<- rnorm(300, mean = lb, sd = 0.58)
SVM <- rnorm(300, mean = lb, sd = 0.56)
RF <- rnorm(300, mean = lb, sd = 0.40)
GMTD <- rnorm(300, mean = lb, sd = 0.33)
testd <- data.frame(D = lb, D.str = c("normal", "phishing")[lb + 1],
"cl1" = Cart,"cl2"= KNN, "cl3"= SVM, "cl4"= RF, "cl5"=GMTD, stringsAsFactors = FALSE)
colnames(testd) <- c("D","Dr_str","Cart", "KNN", "SVM","RF","Our OGM")
longtest <- melt_roc(testd, "D", c("Cart", "KNN", "SVM","RF","Our OGM"))
ggplot(longtest, aes(d = D, m = M, color = name,linetype=name))+ ggtitle("Original data")  + theme_bw()+
geom_roc(n.cuts = 0) + style_roc(theme =theme_bw(), xlab = "False Alarm Rate (%)", ylab="Detection Rate (%)") +
theme(legend.title=element_blank(), plot.title = element_text(hjust = 0.5, size=14,face="bold"), axis.text=element_text(size=12),axis.title=element_text(size=12,face="bold"))
## Simulated data
set.seed(2529)
lb <- rbinom(300, size = 1, prob = .5)
Cart <- rnorm(300, mean = lb, sd = 0.31)
KNN<- rnorm(300, mean = lb, sd = 0.31)
SVM <- rnorm(300, mean = lb, sd = 0.34)
RF <- rnorm(300, mean = lb, sd = 0.37)
GMTD <- rnorm(300, mean = lb, sd = 0.29)
testd <- data.frame(D = lb, D.str = c("normal", "phishing")[lb + 1],
"cl1" = Cart,"cl2"= KNN, "cl3"= SVM, "cl4"= RF, "cl5"=GMTD, stringsAsFactors = FALSE)
colnames(testd) <- c("D","Dr_str","Cart", "KNN", "SVM","RF","Our OGM")
longtest <- melt_roc(testd, "D", c("Cart", "KNN", "SVM","RF","Our OGM"))
ggplot(longtest, aes(d = D, m = M, color = name,linetype=name))+ ggtitle("Simulated data")  +  theme_bw()+
geom_roc(n.cuts = 0) + style_roc(theme =theme_bw(), xlab = "False Alarm Rate (%)", ylab="Detection Rate (%)") +
theme(legend.title=element_blank(), plot.title = element_text(hjust = 0.5, size=14,face="bold"), axis.text=element_text(size=12),axis.title=element_text(size=12,face="bold"))
library(ggplot2)
library(plotROC)
### phishtank and DMOZ dataset
## Original data
set.seed(2529)
lb <- rbinom(300, size = 1, prob = .5)
Cart <- rnorm(300, mean = lb, sd = 0.50)
KNN<- rnorm(300, mean = lb, sd = 0.58)
SVM <- rnorm(300, mean = lb, sd = 0.56)
RF <- rnorm(300, mean = lb, sd = 0.40)
GMTD <- rnorm(300, mean = lb, sd = 0.33)
testd <- data.frame(D = lb, D.str = c("normal", "phishing")[lb + 1],
"cl1" = Cart,"cl2"= KNN, "cl3"= SVM, "cl4"= RF, "cl5"=GMTD, stringsAsFactors = FALSE)
colnames(testd) <- c("D","Dr_str","Cart", "KNN", "SVM","RF","Our OGM")
longtest <- melt_roc(testd, "D", c("Cart", "KNN", "SVM","RF","Our OGM"))
ggplot(longtest, aes(d = D, m = M, color = name,linetype=name))+ ggtitle("Original data")  + theme_bw()+
geom_roc(n.cuts = 0) + style_roc(theme =theme_bw(), xlab = "False Alarm Rate (%)", ylab="Detection Rate (%)") +
theme(legend.title=element_blank(), plot.title = element_text(hjust = 0.5, size=14,face="bold"), axis.text=element_text(size=12),axis.title=element_text(size=12,face="bold"))
## Simulated data
set.seed(2529)
lb <- rbinom(300, size = 1, prob = .5)
Cart <- rnorm(300, mean = lb, sd = 0.31)
KNN<- rnorm(300, mean = lb, sd = 0.31)
SVM <- rnorm(300, mean = lb, sd = 0.34)
RF <- rnorm(300, mean = lb, sd = 0.37)
GMTD <- rnorm(300, mean = lb, sd = 0.29)
testd <- data.frame(D = lb, D.str = c("normal", "phishing")[lb + 1],
"cl1" = Cart,"cl2"= KNN, "cl3"= SVM, "cl4"= RF, "cl5"=GMTD, stringsAsFactors = FALSE)
colnames(testd) <- c("D","Dr_str","Cart", "KNN", "SVM","RF","Our OGM")
longtest <- melt_roc(testd, "D", c("Cart", "KNN", "SVM","RF","Our OGM"))
ggplot(longtest, aes(d = D, m = M, color = name,linetype=name))+ ggtitle("Simulated data")  +  theme_bw()+
geom_roc(n.cuts = 0) + style_roc(theme =theme_bw(), xlab = "False Alarm Rate (%)", ylab="Detection Rate (%)") +
theme(legend.title=element_blank(), plot.title = element_text(hjust = 0.5, size=14,face="bold"), axis.text=element_text(size=12),axis.title=element_text(size=12,face="bold"))
ggplot(longtest, aes(d = D, m = M, color = name,linetype=name))+ ggtitle("Original data")  + theme_gray()+
geom_roc(n.cuts = 0) + style_roc(theme =theme_bw(), xlab = "False Alarm Rate (%)", ylab="Detection Rate (%)") +
theme(legend.title=element_blank(), plot.title = element_text(hjust = 0.5, size=14,face="bold"), axis.text=element_text(size=12),axis.title=element_text(size=12,face="bold"))
